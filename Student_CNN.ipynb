{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1vpdjHhpdsfxhkKx-6EyHGjTSB2F-B3P0","timestamp":1657297266922}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"}},"cells":[{"cell_type":"markdown","metadata":{"id":"TiM6gYg0nhkY"},"source":["<font color=\"#de3023\"><h1><b>REMINDER MAKE A COPY OF THIS NOTEBOOK, DO NOT EDIT</b></h1></font>"]},{"cell_type":"markdown","metadata":{"id":"Sq-JhCcLpBwS"},"source":["#Conscientious Cars 2: Convolutional Neural Nets\n","\n","Welcome back to CC: ConscientiousCars! Today, we'll be improving on our system for distinguishing dogs from roads."]},{"cell_type":"code","metadata":{"id":"uhNVum16scIW","executionInfo":{"status":"ok","timestamp":1657407637662,"user_tz":240,"elapsed":17587,"user":{"displayName":"Ajay Narayanan Anantha Subramanian","userId":"14083184234254748026"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5ff31dbd-42a7-42b9-cc7f-245b8e06b5b1"},"source":["#@title Run this to load some packages and data! { display-mode: \"form\" }\n","import pickle\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn import model_selection\n","from sklearn.metrics import accuracy_score\n","from collections import Counter\n","import keras.api._v2.keras as keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, InputLayer\n","from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape\n","from keras.utils.np_utils import to_categorical \n","!pip install -q git+https://github.com/rdk2132/scikeras # workaround for scikeras deprecation\n","from scikeras.wrappers import KerasClassifier\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import cross_val_score\n","\n","# Quiet deprecation warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\") \n","\n","def categorical_to_numpy(labels_in):\n","  labels = []\n","  for label in labels_in:\n","    if label == 'dog':\n","      labels.append(np.array([1, 0]))\n","    else:\n","      labels.append(np.array([0, 1]))\n","  return np.array(labels)\n","\n","def load_data():\n","  # import the data from the Cloud\n","  !wget -q --show-progress https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%201%20-%205/Session%204%20_%205%20-%20Neural%20Networks%20_%20CNN/dogs_v_roads\n","\n","  # initialize our input and output variables\n","  data_dict = pickle.load(open( \"dogs_v_roads\", \"rb\" ));  \n","  data   = data_dict['data']\n","  labels = data_dict['labels']\n","  \n","  return data, labels\n","\n","\n","def plot_one_image(data, labels, img_idx):\n","  from google.colab.patches import cv2_imshow\n","  import cv2\n","  import matplotlib.pyplot as plt\n","  my_img   = data[img_idx, :].squeeze().reshape([32,32,3]).copy()\n","  my_label = labels[img_idx]\n","  print('label: %s'%my_label)\n","  plt.imshow(my_img)\n","  plt.show()\n","  \n","def CNNClassifier(num_epochs=2, layers=1, dropout=0.15):\n","  def create_model():\n","    model = Sequential()\n","    model.add(Reshape((32, 32, 3)))\n","    \n","    for i in range(layers):\n","      model.add(Conv2D(32, (3, 3), padding='same'))\n","      model.add(Activation('relu'))\n","    \n","    model.add(Conv2D(32, (3, 3)))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(dropout))\n","\n","    model.add(Conv2D(64, (3, 3), padding='same'))\n","    model.add(Activation('relu'))\n","    model.add(Conv2D(64, (3, 3)))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(dropout))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512))\n","    model.add(Activation('relu'))\n","    model.add(Dropout(dropout))\n","    model.add(Dense(2))\n","    model.add(Activation('softmax'))\n","\n","    return model\n","  # initiate RMSprop optimizer\n","  opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n","  return KerasClassifier(model=create_model, optimizer=opt, loss='categorical_crossentropy', epochs=num_epochs, batch_size=10, verbose=2, validation_batch_size=10, validation_split=.2, metrics=['accuracy'])\n","\n","def plot_acc_scikeras(history, ax = None, xlabel = 'Epoch #'):\n","    history = history.history_\n","    history.update({'epoch':list(range(len(history['val_accuracy'])))})\n","    history = pd.DataFrame.from_dict(history)\n","\n","    best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n","\n","    if not ax:\n","      f, ax = plt.subplots(1,1)\n","    sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n","    sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n","    ax.axhline(0.5, linestyle = '--',color='red', label = 'Chance')\n","    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')  \n","    ax.legend(loc = 7)    \n","    ax.set_ylim([0.4, 1])\n","\n","    ax.set_xlabel(xlabel)\n","    ax.set_ylabel('Accuracy (Fraction)')\n","    \n","    plt.show()\n","    \n","def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n","    history = history.history_\n","    history.update({'epoch':list(range(len(history['val_accuracy'])))})\n","    history = pd.DataFrame.from_dict(history)\n","\n","    best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n","\n","    if not ax:\n","      f, ax = plt.subplots(1,1)\n","    sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n","    sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n","    ax.axhline(0.5, linestyle = '--',color='red', label = 'Chance')\n","    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')  \n","    ax.legend(loc = 7)    \n","    ax.set_ylim([0.4, 1])\n","\n","    ax.set_xlabel(xlabel)\n","    ax.set_ylabel('Accuracy (Fraction)')\n","    \n","    plt.show()\n","\n","def model_to_string(model):\n","    import re\n","    stringlist = []\n","    model.summary(print_fn=lambda x: stringlist.append(x))\n","    sms = \"\\n\".join(stringlist)\n","    sms = re.sub('_\\d\\d\\d','', sms)\n","    sms = re.sub('_\\d\\d','', sms)\n","    sms = re.sub('_\\d','', sms)  \n","    return sms"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"markdown","metadata":{"id":"wkseZ14ms7vs"},"source":["In this notebook, we will:\n","\n","- Use a pre-built CNN function to classify roads vs. dogs.\n","- Build neural networks from scratch in Keras.\n","- Experiment with building CNN models from scratch in Keras.\n","- (Advanced, Optional) Build CNN models for distinguishing cats from dogs, and even experiment with implementing a famous architecture!\n"]},{"cell_type":"markdown","metadata":{"id":"qMWQRlTqt6Yn"},"source":["<font color=darkorange>**Change Hardware Accelerator to GPU to train faster (Runtime -> Change Runtime Type -> Hardware Accelerator -> GPU)**"]},{"cell_type":"markdown","metadata":{"id":"1QxGsnvhnn8R"},"source":["#Loading in Data"]},{"cell_type":"markdown","metadata":{"id":"btr24O6Hqgo6"},"source":["Once again, let's load in our dog/road dataset and create our training and test set. **What's the shape of each dataset? Why?**"]},{"cell_type":"code","metadata":{"id":"MmZbrZoKnthN","executionInfo":{"status":"ok","timestamp":1657407638055,"user_tz":240,"elapsed":396,"user":{"displayName":"Ajay Narayanan Anantha Subramanian","userId":"14083184234254748026"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5c50b3fa-44fe-454f-e404-da8e191e87c0"},"source":["# load our data\n","data_raw, labels_raw = load_data()\n","data = data_raw.astype(float)\n","labels = categorical_to_numpy(labels_raw)\n","inputs_train, inputs_test, labels_train, labels_test = model_selection.train_test_split(data, labels, test_size=0.2, random_state=1)\n","\n","#Find the shape of our dataset!\n","### YOUR CODE HERE\n","print(data.shape)\n","print(data)\n","### END CODE"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\rdogs_v_roads.1        0%[                    ]       0  --.-KB/s               \rdogs_v_roads.1      100%[===================>]   3.52M  --.-KB/s    in 0.02s   \n","(1200, 3072)\n","[[ 45.  20.  19. ...  83.  99.  31.]\n"," [101. 114.  35. ... 155. 134.  91.]\n"," [213. 221. 221. ... 139.  58.  47.]\n"," ...\n"," [126. 174. 202. ... 124. 128. 129.]\n"," [191. 232. 240. ...  74.  93.  81.]\n"," [237. 248. 254. ...  45.  56.  10.]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"VcZra2S0NNSZ"},"source":["Use the cell below as a reminder of what the data looks like."]},{"cell_type":"code","metadata":{"id":"B83F3CmPNSux","executionInfo":{"status":"ok","timestamp":1657407638056,"user_tz":240,"elapsed":6,"user":{"displayName":"Ajay Narayanan Anantha Subramanian","userId":"14083184234254748026"}},"colab":{"base_uri":"https://localhost:8080/","height":283},"outputId":"636190b5-cc46-4a91-87a6-4010fb191f00"},"source":["plot_one_image(data_raw, labels_raw, 300) # change this number"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["label: dog\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"37O_VE_D1Bdy"},"source":["# Models for Vision: Convolutional Neural Networks"]},{"cell_type":"markdown","metadata":{"id":"GqrfI4JiVeFr"},"source":["###Exercise: Exploring Hyperparameters ✍️\n","\n","As you know, there is a famous type of neural network known as convolutional neural networks (CNNs). These types of neural networks work particularly well on problems to do with computer vision. Let's try one out!\n","\n","To load up a simple CNN on scikit-learn, just run:\n","\n","`cnn = CNNClassifier(num_epochs, layers, dropout)`\n","\n","Work with your instructors to review what each parameter means and how it affects the model! The value for **dropout** is a float between 0 and 1 that represents the probability the weight for a neuron in the layer is set to 0 during training time. Each neuron in the layer is evaluated as such, which can help prevent overfitting.\n","\n","**Try different values of num_epochs, layers, and dropout so that you get the best possible accuracy on the test set using `model.score()`**!"]},{"cell_type":"code","metadata":{"id":"bmC3-T4KRJgW","executionInfo":{"status":"ok","timestamp":1657407642007,"user_tz":240,"elapsed":3954,"user":{"displayName":"Ajay Narayanan Anantha Subramanian","userId":"14083184234254748026"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6a29dbb2-5a4b-420c-a3e7-d69e61531e2e"},"source":["cnn = CNNClassifier(5, 2, 0.5)\n","cnn.fit(inputs_train, labels_train)\n","preds = cnn.predict(inputs_test)\n","print(cnn.score(inputs_test, labels_test))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","77/77 - 2s - loss: 7.5618 - accuracy: 0.5690 - val_loss: 0.5003 - val_accuracy: 0.8021 - 2s/epoch - 22ms/step\n","Epoch 2/5\n","77/77 - 0s - loss: 1.0730 - accuracy: 0.7344 - val_loss: 0.3881 - val_accuracy: 0.8281 - 426ms/epoch - 6ms/step\n","Epoch 3/5\n","77/77 - 0s - loss: 0.5007 - accuracy: 0.8346 - val_loss: 0.2315 - val_accuracy: 0.8958 - 432ms/epoch - 6ms/step\n","Epoch 4/5\n","77/77 - 0s - loss: 0.3400 - accuracy: 0.8646 - val_loss: 0.3354 - val_accuracy: 0.8333 - 462ms/epoch - 6ms/step\n","Epoch 5/5\n","77/77 - 0s - loss: 0.2839 - accuracy: 0.8880 - val_loss: 0.1757 - val_accuracy: 0.9323 - 439ms/epoch - 6ms/step\n","24/24 - 0s - 127ms/epoch - 5ms/step\n","24/24 - 0s - 54ms/epoch - 2ms/step\n","0.9166666666666666\n"]}]},{"cell_type":"markdown","metadata":{"id":"KGWpgsVXP1ut"},"source":["**How well did your neural network perform?** \n","\n","CNNs typically perform better than fully-connected neural networks on vision problems, but, as before, they aren't always consistent. They are also sensitive to a number of parameters. "]},{"cell_type":"markdown","metadata":{"id":"c-XRh5Y5P_CL"},"source":["## Training and Validation Curves\n","\n","An important aspect of training neural networks is to prevent overfitting. **How would we recognize overfitting?**\n","\n","In the first line of code below, we first **fit** the model on the training data and pass in some validation (or test) data to evaluate it. We call it the **history** because we want to retain information about the accuracy at each epoch.\n","\n","In the second line we plot the history so that we can compare the training and validation accuracies.  \n","\n","```\n","history = model.fit(inputs_train, labels_train, validation_data=(inputs_test, labels_test))\n","plot_acc_scikeras(history)\n","```"]},{"cell_type":"markdown","metadata":{"id":"8eaFvE2PQEFe"},"source":["###Exercise: Plotting a Training vs. Validation Curve For Our CNN ✍️\n","\n","**After how many epochs does the model begin to overfit? How does this vary as you vary the number of hidden layers and dropout?** Overfitting occurs when the validation accuracy starts to drop below the training accuracy."]},{"cell_type":"code","metadata":{"id":"OsVAasDbjARJ","colab":{"base_uri":"https://localhost:8080/","height":769},"executionInfo":{"status":"ok","timestamp":1657407652432,"user_tz":240,"elapsed":10432,"user":{"displayName":"Ajay Narayanan Anantha Subramanian","userId":"14083184234254748026"}},"outputId":"8ae3c701-cc23-4250-ec6b-e1e0482c640d"},"source":["cnn = CNNClassifier(num_epochs=14, layers=6, dropout=0.5)\n","\n","history = cnn.fit(inputs_train, labels_train, \n","                  validation_data=(inputs_test, labels_test))\n","plot_acc(history)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/14\n","77/77 - 2s - loss: 0.9556 - accuracy: 0.5924 - val_loss: 0.5051 - val_accuracy: 0.7135 - 2s/epoch - 29ms/step\n","Epoch 2/14\n","77/77 - 1s - loss: 0.4011 - accuracy: 0.8151 - val_loss: 0.3641 - val_accuracy: 0.8281 - 570ms/epoch - 7ms/step\n","Epoch 3/14\n","77/77 - 1s - loss: 0.2807 - accuracy: 0.8893 - val_loss: 0.2423 - val_accuracy: 0.8958 - 568ms/epoch - 7ms/step\n","Epoch 4/14\n","77/77 - 1s - loss: 0.2308 - accuracy: 0.9062 - val_loss: 0.2184 - val_accuracy: 0.9167 - 656ms/epoch - 9ms/step\n","Epoch 5/14\n","77/77 - 1s - loss: 0.2140 - accuracy: 0.9245 - val_loss: 0.2047 - val_accuracy: 0.9323 - 571ms/epoch - 7ms/step\n","Epoch 6/14\n","77/77 - 1s - loss: 0.2100 - accuracy: 0.9180 - val_loss: 0.2772 - val_accuracy: 0.9010 - 559ms/epoch - 7ms/step\n","Epoch 7/14\n","77/77 - 1s - loss: 0.1826 - accuracy: 0.9375 - val_loss: 0.1761 - val_accuracy: 0.9167 - 575ms/epoch - 7ms/step\n","Epoch 8/14\n","77/77 - 1s - loss: 0.1526 - accuracy: 0.9401 - val_loss: 0.1477 - val_accuracy: 0.9323 - 568ms/epoch - 7ms/step\n","Epoch 9/14\n","77/77 - 1s - loss: 0.1573 - accuracy: 0.9388 - val_loss: 0.1183 - val_accuracy: 0.9583 - 547ms/epoch - 7ms/step\n","Epoch 10/14\n","77/77 - 1s - loss: 0.1388 - accuracy: 0.9505 - val_loss: 0.1100 - val_accuracy: 0.9688 - 561ms/epoch - 7ms/step\n","Epoch 11/14\n","77/77 - 1s - loss: 0.1465 - accuracy: 0.9531 - val_loss: 0.1371 - val_accuracy: 0.9375 - 553ms/epoch - 7ms/step\n","Epoch 12/14\n","77/77 - 1s - loss: 0.1489 - accuracy: 0.9440 - val_loss: 0.1082 - val_accuracy: 0.9531 - 556ms/epoch - 7ms/step\n","Epoch 13/14\n","77/77 - 1s - loss: 0.1134 - accuracy: 0.9570 - val_loss: 0.1110 - val_accuracy: 0.9583 - 706ms/epoch - 9ms/step\n","Epoch 14/14\n","77/77 - 1s - loss: 0.1043 - accuracy: 0.9635 - val_loss: 0.0993 - val_accuracy: 0.9583 - 867ms/epoch - 11ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["# Print the score on the testing data\n","print(\"CNN Testing Set Score:\")\n","print(cnn.score(inputs_test, labels_test))"],"metadata":{"id":"zEYUz17TJCGX","executionInfo":{"status":"ok","timestamp":1657407653252,"user_tz":240,"elapsed":826,"user":{"displayName":"Ajay Narayanan Anantha Subramanian","userId":"14083184234254748026"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"64332682-b438-465c-e543-e213aac434a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CNN Testing Set Score:\n","24/24 - 0s - 287ms/epoch - 12ms/step\n","0.9708333333333333\n"]}]},{"cell_type":"markdown","metadata":{"id":"76z4NAY6afd7"},"source":["# Building Neural Networks from Scratch in Keras \n","\n","So far, we've used helper functions which pre-build Keras neural network models. Now, we will build them on our own!\n","\n","Let's start with a \"toy example\": a tiny neural network with just three numerical inputs.\n"]},{"cell_type":"markdown","metadata":{"id":"jdngkAX_aCVu"},"source":["###Exercise: Building a Simple Neural Network Using Keras! ✍️\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Bj-Pt3wGCXRu"},"source":["\n","We're going to build this model: \n","\n","![](http://cs231n.github.io/assets/nn1/neural_net.jpeg)"]},{"cell_type":"markdown","metadata":{"id":"H-6WGeedvTCS"},"source":["This network can be described as: \n","* Input Layer: 3 neurons\n","* Layer 1 (Hidden): 4 neurons that are activated by `'relu'`\n","* Layer 2 (Output): 2 neurons that are activated by `'softmax'`\n","\n","\n","We also want to compile the model with\n","`loss = 'categorical_crossentropy'`\n","\n","What does this represent? Here's one way to interpret it:\n","* This model classifies animals as \"cat\" or \"dog\"\n","* Our three inputs are height, weight, and age\n","* Our ouputs represent \"probability of cat\" and \"probability of dog\"\n","* Because this is a toy example, we aren't actually training the model here - just using randomly initialized weights! We will train later models in this notebook.\n","\n","Try filling in the blanks below and walking through each line! **If you want a hint or more details, check out the optional reference below.**"]},{"cell_type":"code","metadata":{"id":"dp-g9qotbRPU","executionInfo":{"status":"ok","timestamp":1657407653252,"user_tz":240,"elapsed":6,"user":{"displayName":"Ajay Narayanan Anantha Subramanian","userId":"14083184234254748026"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9ad03b6c-c6a1-40bd-f8c8-84aa1137dd5b"},"source":["# Fill in the blanks with your group!\n","### YOUR CODE HERE:\n","model_1 = Sequential()\n","model_1.add(InputLayer(input_shape=(3,)))\n","model_1.add(Dense(4, activation = 'relu'))\n","model_1.add(Dense(2, activation = 'softmax'))\n","model_1.compile(loss='categorical_crossentropy',\n","                optimizer = 'adam', \n","                metrics = ['accuracy'])\n","model_1.predict([[14,18,5]]) #Try any input! This represents an animal of height 14, weight 18, and age 5.\n","### END CODE"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.95958525, 0.04041475]], dtype=float32)"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"baWZ9zXtF2Cz"},"source":["**Discuss:** How would you interpret this output? Does our (untrained) network classify this as a cat or a dog?"]},{"cell_type":"markdown","metadata":{"id":"781M4IyhssuA"},"source":["####**Optional Reference**\n","\n","Here's some information about each step of the process. **You don't need to read through all this - check it as a reference if needed!**\n","\n","**1. Specify model**\n","\n","```\n","model = Sequential()\n","```\n","In this line of code, we build our network where the information flows from LEFT to RIGHT through the network in ONE DIRECTION as opposed to multiple directions. Neurons on the right never pass informations to neurons on the left of it. \n","\n","\n","**2. Add layers to the network**\n","```\n","model.add(Dense(4, activation = 'sigmoid'))\n","```\n","In this code, we add a layer of neurons to our network. \n","\n","This layers consists of 4 neurons. Each neuron is DENSE and connects to all of the previous layer's inputs and all of the subsequent layers outputs. We specify that there are 3 inputs here.\n","\n","We also specify what kind of output the neuron will give. If you want the neuron to output a number between 0 and 1 (like a probability!) you would use 'softmax' or 'sigmoid'. If you want the neuron to output any number, you can use 'linear'! You'll also often see 'relu', which is when a neuron will only output positive numbers. \n","\n","```\n","model.add(Dense(1, activation = 'linear'))\n","```\n","This code adds ANOTHER layer to the network that has 1 neuron. This one neuron is used to predict a continuous value!\n","\n","**3. Turn the model on by compiling it** \n","\n","After having built the network, we want to train and use it, so we have to 'compile' it to prepare. We have to specify at the very least: a loss (how the model measures the quality of its weights), an optimizer (which adjusts the weights), and a metric (how to evaluate our results). Here are some common choices:\n","```\n","model.compile(loss='mean_squared_error',\n","optimizer = 'adam',\n","metrics = ['mean_squared_error'])\n","  ```\n","\n","Once we've created our network, we can use it very simply! Just like we did with sklearn, we define our input data (x), the true predictions from that data (y), and then train our model with `fit`. \n","\n","```\n","model.fit(x, y)\n","```\n","\n","To use the model, you can use it to predict something with:\n","```\n","y = model.predict(x)\n","```\n","\n","You can actually use the model before you even train it! It just won't perform very well. "]},{"cell_type":"markdown","metadata":{"id":"YovNRgfuy0Oq"},"source":["###(Optional) Exercise: Building a Multi-layer Neural Net Using Keras ✍️\n","\n","![](http://cs231n.github.io/assets/nn1/neural_net2.jpeg)\n","\n","Let's try another, bigger example!\n","\n","Here, we are predicting a house price: regression! Our inputs could be \"year the house was built\", \"home square footage\", and \"lot square footage\", while our output is price (in thousands of dollars).\n","\n","* Input Layer: 3 neurons\n","\n","* Layer 1: 4 neurons that are activated by `'relu' `and take in 3 inputs.\n","\n","* Layer 2: 4 neurons that are activated by `'relu'`\n","\n","* Layer 3 (out): 1 neuron that is activated by `'relu'`\n","\n","Compile the model with\n","`'mean_squared_error'` as both loss and metric, and try making a prediction for some made-up data.\n"]},{"cell_type":"code","metadata":{"id":"pm-ylEWqbXrQ","executionInfo":{"status":"ok","timestamp":1657407653252,"user_tz":240,"elapsed":3,"user":{"displayName":"Ajay Narayanan Anantha Subramanian","userId":"14083184234254748026"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b4e07dec-75c8-470d-d8ee-bad2e8da0371"},"source":["### YOUR CODE HERE\n","model_2 = Sequential()\n","model_2.add(InputLayer(input_shape=(3,)))\n","model_2.add(Dense(4, activation = 'relu'))\n","model_2.add(Dense(4, activation = 'relu'))\n","model_2.add(Dense(1, activation = 'relu'))\n","model_2.compile(loss='mean_squared_error',\n","optimizer = 'adam', \n","metrics = ['mean_squared_error'])\n","\n","model_2.predict([[2012, 1000, 1400]]) \n","#This house was built in 2012, is 1000 square feet, and has 1400 square feet of land.\n","### END CODE"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[310.14185]], dtype=float32)"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"YVCmntRHRjPQ"},"source":["###(Optional) Exercise: Dogs vs. Roads Using Keras\n","\n","Let's try an even bigger example! Here, we are going to distinguish between images of dogs and roads once again. \n","\n","* Input Layer: 3072 dimensions (32 pixels x 32 pixels x 3 color channels)\n","\n","* Layer 1: 32 neurons that are activated by `'relu' `and take in 3072 inputs.\n","\n","* Layer 2: 16 neurons that are activated by `'relu'`\n","\n","* Layer 3 (out): 2 neurons that is activated by `'sigmoid'`\n","\n","Compile the model with\n","`loss = 'binary_crossentropy'`, and try making predictions on `inputs_train`!\n","\n","Once again, we are not actually training this model - so the predictions won't be any good. Soon we will create a CNN, which we will train!"]},{"cell_type":"code","metadata":{"id":"DD2Dc4AYR31r"},"source":["### YOUR CODE HERE\n","\n","### END CODE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QCbD6siv-Ip-"},"source":["##Exercise: Building a CNN Using Keras! ✍️\n","\n","Now that we know how to build simple neural networks in Keras, let's build a CNN! The CNN will perform well on our data set of car and road images. \n","\n","Below is Keras code for a CNN. It will run as-is on the conscientious cars dataset. However, the performance is suboptimal. Add more layers and change the neural network hyperparameters so that the performance will be better. **Can you get the train and validation accuracy to both be higher than 95%?**\n","\n","The Keras core layer API may be a useful reference: https://keras.io/layers/core/ \n","\n","In particular and in addition to adding more of the existing convolutional layers and activations, consider using the following layers after a convolution + activation:\n","\n","`Dropout(N)`\n","\n","`MaxPooling2D(pool_size=(N, N))`\n"]},{"cell_type":"code","metadata":{"id":"LFVHyPKn-V4N","executionInfo":{"status":"error","timestamp":1657407697680,"user_tz":240,"elapsed":44430,"user":{"displayName":"Ajay Narayanan Anantha Subramanian","userId":"14083184234254748026"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"60a5fe8c-eb65-49f9-d77f-173bbc8f2f7b"},"source":["model = Sequential()\n","model.add(Reshape((32, 32, 3)))\n","\n","model.add(Conv2D(32, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","\n","model.add(Conv2D(32, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","\n","model.add(Conv2D(32, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","\n","model.add(Conv2D(32, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","\n","model.add(Conv2D(32, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.5))\n","\n","model.add(Conv2D(64, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.5))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(2))\n","model.add(Activation('softmax'))\n","\n","# initiate RMSprop optimizer\n","opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n","\n","# Let's train the model using RMSprop\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","# Train the CNN and plot accuracy.\n","history = model.fit(inputs_train, labels_train, \\\n","                    validation_data=(inputs_test, labels_test), \\\n","                    epochs=70)\n","plot_acc(history)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/70\n","30/30 [==============================] - 4s 33ms/step - loss: 4.0595 - accuracy: 0.5625 - val_loss: 0.4621 - val_accuracy: 0.8208\n","Epoch 2/70\n","30/30 [==============================] - 0s 15ms/step - loss: 0.8499 - accuracy: 0.6906 - val_loss: 0.4331 - val_accuracy: 0.7958\n","Epoch 3/70\n","30/30 [==============================] - 0s 12ms/step - loss: 0.5212 - accuracy: 0.7708 - val_loss: 0.3112 - val_accuracy: 0.8833\n","Epoch 4/70\n","30/30 [==============================] - 0s 15ms/step - loss: 0.4228 - accuracy: 0.8167 - val_loss: 0.2772 - val_accuracy: 0.8792\n","Epoch 5/70\n","30/30 [==============================] - 0s 14ms/step - loss: 0.3096 - accuracy: 0.8750 - val_loss: 0.2099 - val_accuracy: 0.9250\n","Epoch 6/70\n","30/30 [==============================] - 0s 13ms/step - loss: 0.2927 - accuracy: 0.8740 - val_loss: 0.2195 - val_accuracy: 0.9125\n","Epoch 7/70\n","30/30 [==============================] - 0s 15ms/step - loss: 0.2906 - accuracy: 0.8771 - val_loss: 0.1996 - val_accuracy: 0.9375\n","Epoch 8/70\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2381 - accuracy: 0.8969 - val_loss: 0.1871 - val_accuracy: 0.9417\n","Epoch 9/70\n","30/30 [==============================] - 0s 16ms/step - loss: 0.2350 - accuracy: 0.9062 - val_loss: 0.1630 - val_accuracy: 0.9667\n","Epoch 10/70\n","30/30 [==============================] - 0s 14ms/step - loss: 0.2399 - accuracy: 0.9083 - val_loss: 0.1975 - val_accuracy: 0.9417\n","Epoch 11/70\n","30/30 [==============================] - 0s 13ms/step - loss: 0.2163 - accuracy: 0.9104 - val_loss: 0.1501 - val_accuracy: 0.9667\n","Epoch 12/70\n","30/30 [==============================] - 0s 13ms/step - loss: 0.1848 - accuracy: 0.9323 - val_loss: 0.2426 - val_accuracy: 0.8917\n","Epoch 13/70\n","30/30 [==============================] - 0s 13ms/step - loss: 0.1968 - accuracy: 0.9240 - val_loss: 0.1446 - val_accuracy: 0.9667\n","Epoch 14/70\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1672 - accuracy: 0.9302 - val_loss: 0.1513 - val_accuracy: 0.9667\n","Epoch 15/70\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1755 - accuracy: 0.9344 - val_loss: 0.2128 - val_accuracy: 0.9125\n","Epoch 16/70\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1717 - accuracy: 0.9312 - val_loss: 0.1634 - val_accuracy: 0.9375\n","Epoch 17/70\n","30/30 [==============================] - 0s 16ms/step - loss: 0.1681 - accuracy: 0.9302 - val_loss: 0.1513 - val_accuracy: 0.9583\n","Epoch 18/70\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1529 - accuracy: 0.9396 - val_loss: 0.1393 - val_accuracy: 0.9667\n","Epoch 19/70\n","30/30 [==============================] - 0s 15ms/step - loss: 0.1382 - accuracy: 0.9458 - val_loss: 0.1913 - val_accuracy: 0.9292\n","Epoch 20/70\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1380 - accuracy: 0.9448 - val_loss: 0.1249 - val_accuracy: 0.9667\n","Epoch 21/70\n","30/30 [==============================] - 1s 19ms/step - loss: 0.1418 - accuracy: 0.9427 - val_loss: 0.1114 - val_accuracy: 0.9792\n","Epoch 22/70\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1254 - accuracy: 0.9604 - val_loss: 0.1070 - val_accuracy: 0.9792\n","Epoch 23/70\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1215 - accuracy: 0.9604 - val_loss: 0.1153 - val_accuracy: 0.9583\n","Epoch 24/70\n","30/30 [==============================] - 0s 14ms/step - loss: 0.1147 - accuracy: 0.9531 - val_loss: 0.1007 - val_accuracy: 0.9833\n","Epoch 25/70\n","30/30 [==============================] - 0s 17ms/step - loss: 0.1075 - accuracy: 0.9604 - val_loss: 0.1020 - val_accuracy: 0.9875\n","Epoch 26/70\n","30/30 [==============================] - 0s 13ms/step - loss: 0.1143 - accuracy: 0.9573 - val_loss: 0.1232 - val_accuracy: 0.9792\n","Epoch 27/70\n","30/30 [==============================] - 0s 17ms/step - loss: 0.1310 - accuracy: 0.9531 - val_loss: 0.1171 - val_accuracy: 0.9750\n","Epoch 28/70\n","30/30 [==============================] - 1s 18ms/step - loss: 0.1116 - accuracy: 0.9646 - val_loss: 0.1211 - val_accuracy: 0.9708\n","Epoch 29/70\n","30/30 [==============================] - 0s 15ms/step - loss: 0.0983 - accuracy: 0.9635 - val_loss: 0.1552 - val_accuracy: 0.9542\n","Epoch 30/70\n","30/30 [==============================] - 1s 17ms/step - loss: 0.1051 - accuracy: 0.9604 - val_loss: 0.1159 - val_accuracy: 0.9750\n","Epoch 31/70\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0983 - accuracy: 0.9708 - val_loss: 0.1763 - val_accuracy: 0.9417\n","Epoch 32/70\n","30/30 [==============================] - 0s 16ms/step - loss: 0.0915 - accuracy: 0.9698 - val_loss: 0.1206 - val_accuracy: 0.9833\n","Epoch 33/70\n","30/30 [==============================] - 0s 12ms/step - loss: 0.0861 - accuracy: 0.9646 - val_loss: 0.1595 - val_accuracy: 0.9750\n","Epoch 34/70\n","30/30 [==============================] - 0s 10ms/step - loss: 0.0667 - accuracy: 0.9771 - val_loss: 0.1294 - val_accuracy: 0.9750\n","Epoch 35/70\n","30/30 [==============================] - 0s 11ms/step - loss: 0.0959 - accuracy: 0.9688 - val_loss: 0.1306 - val_accuracy: 0.9500\n","Epoch 36/70\n","30/30 [==============================] - 0s 11ms/step - loss: 0.0719 - accuracy: 0.9792 - val_loss: 0.1211 - val_accuracy: 0.9833\n","Epoch 37/70\n","30/30 [==============================] - 0s 10ms/step - loss: 0.1012 - accuracy: 0.9688 - val_loss: 0.1136 - val_accuracy: 0.9833\n","Epoch 38/70\n","30/30 [==============================] - 0s 11ms/step - loss: 0.0688 - accuracy: 0.9760 - val_loss: 0.1200 - val_accuracy: 0.9833\n","Epoch 39/70\n","30/30 [==============================] - 0s 10ms/step - loss: 0.0677 - accuracy: 0.9812 - val_loss: 0.1438 - val_accuracy: 0.9750\n","Epoch 40/70\n","30/30 [==============================] - 0s 10ms/step - loss: 0.0703 - accuracy: 0.9750 - val_loss: 0.1515 - val_accuracy: 0.9583\n","Epoch 41/70\n","30/30 [==============================] - 0s 10ms/step - loss: 0.0609 - accuracy: 0.9781 - val_loss: 0.1577 - val_accuracy: 0.9708\n","Epoch 42/70\n","30/30 [==============================] - 0s 10ms/step - loss: 0.0615 - accuracy: 0.9781 - val_loss: 0.1454 - val_accuracy: 0.9792\n","Epoch 43/70\n","30/30 [==============================] - 0s 10ms/step - loss: 0.0656 - accuracy: 0.9719 - val_loss: 0.1661 - val_accuracy: 0.9667\n","Epoch 44/70\n","30/30 [==============================] - 0s 11ms/step - loss: 0.0631 - accuracy: 0.9781 - val_loss: 0.1413 - val_accuracy: 0.9417\n","Epoch 45/70\n","30/30 [==============================] - 0s 10ms/step - loss: 0.0672 - accuracy: 0.9792 - val_loss: 0.1515 - val_accuracy: 0.9708\n","Epoch 46/70\n","30/30 [==============================] - 0s 11ms/step - loss: 0.0640 - accuracy: 0.9792 - val_loss: 0.1243 - val_accuracy: 0.9792\n","Epoch 47/70\n","30/30 [==============================] - 0s 10ms/step - loss: 0.0746 - accuracy: 0.9760 - val_loss: 0.1249 - val_accuracy: 0.9833\n","Epoch 48/70\n","30/30 [==============================] - 0s 10ms/step - loss: 0.0553 - accuracy: 0.9781 - val_loss: 0.1747 - val_accuracy: 0.9500\n","Epoch 49/70\n","30/30 [==============================] - 0s 10ms/step - loss: 0.0613 - accuracy: 0.9854 - val_loss: 0.1227 - val_accuracy: 0.9833\n","Epoch 50/70\n","30/30 [==============================] - 0s 10ms/step - loss: 0.0629 - accuracy: 0.9771 - val_loss: 0.1255 - val_accuracy: 0.9708\n","Epoch 51/70\n","30/30 [==============================] - 0s 10ms/step - loss: 0.0576 - accuracy: 0.9844 - val_loss: 0.1083 - val_accuracy: 0.9750\n","Epoch 52/70\n","30/30 [==============================] - 0s 10ms/step - loss: 0.0499 - accuracy: 0.9781 - val_loss: 0.1447 - val_accuracy: 0.9542\n","Epoch 53/70\n","30/30 [==============================] - 0s 11ms/step - loss: 0.0450 - accuracy: 0.9833 - val_loss: 0.1094 - val_accuracy: 0.9750\n","Epoch 54/70\n","30/30 [==============================] - 0s 11ms/step - loss: 0.0403 - accuracy: 0.9833 - val_loss: 0.1165 - val_accuracy: 0.9667\n","Epoch 55/70\n","30/30 [==============================] - 0s 11ms/step - loss: 0.0645 - accuracy: 0.9771 - val_loss: 0.1106 - val_accuracy: 0.9833\n","Epoch 56/70\n","30/30 [==============================] - 0s 10ms/step - loss: 0.0355 - accuracy: 0.9865 - val_loss: 0.1472 - val_accuracy: 0.9750\n","Epoch 57/70\n","30/30 [==============================] - 0s 11ms/step - loss: 0.0370 - accuracy: 0.9875 - val_loss: 0.1120 - val_accuracy: 0.9792\n","Epoch 58/70\n","30/30 [==============================] - 0s 11ms/step - loss: 0.0573 - accuracy: 0.9802 - val_loss: 0.1280 - val_accuracy: 0.9792\n","Epoch 59/70\n","30/30 [==============================] - 0s 10ms/step - loss: 0.0507 - accuracy: 0.9823 - val_loss: 0.1114 - val_accuracy: 0.9792\n","Epoch 60/70\n","30/30 [==============================] - 0s 10ms/step - loss: 0.0446 - accuracy: 0.9833 - val_loss: 0.1078 - val_accuracy: 0.9792\n","Epoch 61/70\n","30/30 [==============================] - 0s 11ms/step - loss: 0.0387 - accuracy: 0.9833 - val_loss: 0.1625 - val_accuracy: 0.9667\n","Epoch 62/70\n","30/30 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9917 - val_loss: 0.1426 - val_accuracy: 0.9750\n","Epoch 63/70\n","30/30 [==============================] - 0s 11ms/step - loss: 0.0162 - accuracy: 0.9958 - val_loss: 0.1529 - val_accuracy: 0.9625\n","Epoch 64/70\n","30/30 [==============================] - 0s 11ms/step - loss: 0.0740 - accuracy: 0.9812 - val_loss: 0.2263 - val_accuracy: 0.9583\n","Epoch 65/70\n","30/30 [==============================] - 0s 11ms/step - loss: 0.0518 - accuracy: 0.9833 - val_loss: 0.1354 - val_accuracy: 0.9708\n","Epoch 66/70\n","30/30 [==============================] - 0s 11ms/step - loss: 0.0391 - accuracy: 0.9865 - val_loss: 0.1416 - val_accuracy: 0.9792\n","Epoch 67/70\n","30/30 [==============================] - 0s 10ms/step - loss: 0.0341 - accuracy: 0.9865 - val_loss: 0.2638 - val_accuracy: 0.9417\n","Epoch 68/70\n","30/30 [==============================] - 0s 10ms/step - loss: 0.0491 - accuracy: 0.9823 - val_loss: 0.1222 - val_accuracy: 0.9833\n","Epoch 69/70\n","30/30 [==============================] - 0s 11ms/step - loss: 0.0291 - accuracy: 0.9906 - val_loss: 0.1157 - val_accuracy: 0.9792\n","Epoch 70/70\n","30/30 [==============================] - 0s 11ms/step - loss: 0.0496 - accuracy: 0.9833 - val_loss: 0.1307 - val_accuracy: 0.9792\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-3c52c478b62e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Train the CNN and plot accuracy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mplot_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-caaed3c34365>\u001b[0m in \u001b[0;36mplot_acc\u001b[0;34m(history, ax, xlabel)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Epoch #'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'history_'"]}]},{"cell_type":"markdown","metadata":{"id":"9JFLu0CdXM6K"},"source":["**What interesting observations** do you make from the graph? How many epochs should you train for?\n","\n","We can also print out the structure of our model. What do the parts of the summary mean?"]},{"cell_type":"code","metadata":{"id":"RGwXs3C8YZl-"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YXINPAJvRr9W"},"source":["#Advanced: Cats vs. Dogs with CNN\n","\n","So far, we've trained a CNN to distinguish between small images of cats and small images of dogs. It's more challenging and time-consuming to train CNNs for bigger images or harder tasks, like distinguishing dogs from cats (which look a lot more like dogs than roads do!)\n","\n","In this exercise, you'll adapt your previous model to classify large images of dogs vs. cats, and then try implementing a famous CNN architecture. Along the way, you'll deal with some of the debugging that machine learning engineers often have to handle."]},{"cell_type":"code","metadata":{"id":"6gU39z3jNMAt"},"source":["#@title Run this to load cat and dog data. { display-mode: \"form\" }\n","\n","#Code here from https://colab.research.google.com/github/google/eng-edu/blob/master/ml/pc/exercises/image_classification_part1.ipynb#scrollTo=4PIP1rkmeAYS\n","\n","import tensorflow as tf\n","import os \n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from google.colab.patches import cv2_imshow\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","try:\n","  road_model = model\n","  road_saved = True\n","except NameError:\n","  road_saved = False\n","\n","IMG_SHAPE  = 150  # Our training data consists of images with width of 150 pixels and height of 150 pixels\n","_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n","zip_dir = tf.keras.utils.get_file('cats_and_dogs_filterted.zip', origin=_URL, extract=True)\n","base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered')\n","train_dir = os.path.join(base_dir, 'train')\n","validation_dir = os.path.join(base_dir, 'validation')\n","\n","train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n","train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n","validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n","validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures\n","train_image_generator      = ImageDataGenerator()  # Generator for our training data\n","validation_image_generator = ImageDataGenerator()  # Generator for our validation data\n","train_data = train_image_generator.flow_from_directory(batch_size=2000,\n","                                                           directory=train_dir,\n","                                                           shuffle=True,\n","                                                           target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n","                                                           class_mode='binary').next()\n","val_data = validation_image_generator.flow_from_directory(batch_size=1000,\n","                                                              directory=validation_dir,\n","                                                              shuffle=False,\n","                                                              target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n","\n","                                                              class_mode='binary').next()\n","cd_train_inputs, cd_train_labels = train_data\n","cd_test_inputs, cd_test_labels = val_data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1y5etOJwScaG"},"source":["**Run the code below to see the dimensions of our training and validation data. What does each number mean? What is different than our previous dataset?** "]},{"cell_type":"code","metadata":{"id":"kjdedJ0VNvWg"},"source":["print(cd_train_inputs.shape) \n","print(cd_train_labels.shape) \n","print(cd_test_inputs.shape) \n","print(cd_test_labels.shape) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qIAkgOqWTAL7"},"source":["**Run this code to see a random image from our training data (different each time).**"]},{"cell_type":"code","metadata":{"id":"HooiJ-RrQPcA"},"source":["index = np.random.randint(len(cd_train_inputs))\n","plt.imshow(cd_train_inputs[index]/255)\n","plt.show()\n","print(\"Label:\",cd_train_labels[index])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HOwP9kX9UshH"},"source":["**By adapting code from the previous exercise, build, train, and test a CNN to classify cats vs. dogs.**\n","**Hints:**\n","*   Use print(model.summary()) for a useful visualization of your model's architecture. Compare the summary of your cat/road and cat/dog classifiers.\n","*  Substitute the names of the new datasets.\n","*  Get a \"first try\" working by making small adjustments to a previous model before trying to optimize the accuracy. You can temporarily comment out layers as you figure things out.\n","*  The outputs have different shapes betweeen the two datasets. What do you need to change? (You will get an ValueError that suggests how to transform the output to a one-hot encoding.) \n","*  If you run out of memory, restart the notebook and/or use your knowledge of convolution arithmetic to reduce the size of an intermediate output (see [Keras documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)).\n","* Dropout layers help reduce overfitting.\n"]},{"cell_type":"code","metadata":{"id":"AeuqlzigZZ8I"},"source":["model = Sequential()\n","#TODO: Your code here to build, train, and test a cats vs. dogs CNN!\n","#If you run into errors, see the hints above for help debugging! \n","#\n","#\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m6sFSGEqjPwe"},"source":["#Advanced Challenge: Implementing a Famous Architecture for Cats vs. Dogs\n","\n","Having trouble designing an effective architecture? Try implementing a version of AlexNet, one of the most famous CNNs for image convolution ever. You can find this image and other useful information on this network [here](https://towardsdatascience.com/the-w3h-of-alexnet-vggnet-resnet-and-inception-7baaaecccc96).\n","\n","![](https://lh4.googleusercontent.com/gFAxn9Z-Y1lgkNy2GfsqjXy1DvSuYF8rvP3CslRvmuoP5SUaJMrEOr24YShU_LwalLpYNJFwpJgcDh9whk9XrMOGQ1ADQ9FY_0saicCVH0jsNPDKOYBcTG4YhbqpbPolW4hZSdUsDQ)\n","\n","How do we read this diagram?\n","\n","On the left side, we start with images of dimension 227x227x3 (RGB). We apply a filter composed of 96 kernels of size 11x11, with stride size 4. We end up with data of dimension 55x55x96. We pass through multiple layers of convolution and max pooling as shown, before ending with three dense (fully connected) layers.\n","\n","Not shown: each layer uses ReLU activation, and we include dropout before the first two dense layers. Make sure to include those!\n","\n","You'll want to adjust some of these dimensions, for a few reasons: we're starting with 150x150 rather than 227x227 images, ending with 2 labels rather than 1000, and have limited data and memory. Use your knowledge of convolution arithmetic (see CNN slides) and the [Keras documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) to change the stride, kernel, and/or padding.\n","\n","Use model.summary() to understand the dimensions of your data at each step. To speed things up as you're building, you can set the number of epochs to 1."]},{"cell_type":"code","metadata":{"id":"8FHg8YTGtQ2t"},"source":["model = Sequential()\n","#TODO: Your code to run, train, and test AlexNet here:\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PlF308hDjwyC"},"source":["You might find that even AlexNet isn't working that well for you!\n","\n","This is because having a good architecture is only half the battle: AlexNet is a complex model designed to learn from millions of images. We're using a small dataset of only 2000 training images, so it's not surprising that our results aren't great. Our model is overfitting: essentially memorizing the few training images, rather than really learning the difference between a cat and a dog. (The advantage is that our model trains quickly.)\n","\n","To get really good performance, we need more data. If we can't find more, we could use *data augmentation*: inventing new training data by transforming our existing images. You can read more about it at https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html."]},{"cell_type":"markdown","metadata":{"id":"RVzEpI_xWpE5"},"source":["![](https://images.pexels.com/photos/316/black-and-white-animal-dog-pet.jpg?auto=compress&cs=tinysrgb&dpr=2&h=650&w=940)"]}]}